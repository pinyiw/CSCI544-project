# -*- coding: utf-8 -*-
"""CSCI544_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sBmEttwApsEor9V13QwoxinngwuATt8y
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/CSCI544-project

# install packages
# !pip install summac

import nltk
nltk.download('punkt')
nltk.download('stopwords')
from summac.model_summac import SummaCZS, SummaCConv
import random
from nltk.corpus import stopwords

def extract_sentences(filename):
    doc = []
    with open(filename) as fp:
      for line in fp:
          doc.append(line.rstrip().split("\t")[0])
    with open(filename+"-text", "w") as outfile:
        for line in doc:
            outfile.write(line + " ")
    return doc

# # extract sentences
# doc = []
# with open("restaurant-reviews-example") as fp:
#   for line in fp:
#       doc.append(line.rstrip().split("\t")[0])
# # sum = []
# # with open("restaurant-summary-example") as fp:
# #   for line in fp:
# #       sum.append(line.rstrip().split("\n")[0])
# sum = ["The food is praised.", "Service is praised.", "Ambiance of the restaurant is praised.",\
#        "The food quality is criticized.", "Portion sizes are small.", "Service is poor.", \
#        "Prices of the restaurant is high."]

model_zs = SummaCZS(granularity="sentence", model_name="vitc", device="cuda") # If you have a GPU: switch to: device="cuda"
model_conv = SummaCConv(models=["vitc"], bins='percentile', granularity="sentence", nli_labels="e", device="cuda", start_file="default", agg="mean")

def compute_faithfulness(reviews, summary):
    for sum in summary:
        support = 0
        # reviews_batch = random.sample(reviews, 20)
        for review in reviews:
            score_zs = model_zs.score([review], [sum])['scores'][0]
            if score_zs > 0.2:
                support += 1
        print("summary:", sum)
        print("support:", support)
        print("=====")

def compute_factuality(reviews, summary):
    for sum in summary:
        top_score = 0
        # reviews_batch = random.sample(reviews, 20)
        for review in reviews:
            score_zs = model_zs.score([review], [sum])['scores'][0]
            top_score = max(top_score, score_zs)
        print("summary:", sum)
        print("top score:", top_score)
        print("=====")

# # remove stop words
# stop_words = set(stopwords.words('english'))
# sums = []
# sum1 = []
# with open("yelp-1-sum") as fp:
#     for line in fp:
#         s = line.rstrip().split("\n")[0]
#         s = s.rstrip().split(" ")
#         for word in s:
#             if not word in stop_words:
#                 sum1.append(word)
# sums.append(sum1)
# sum2 = []
# with open("yelp-2-sum") as fp:
#     for line in fp:
#         s = line.rstrip().split("\n")[0]
#         s = s.rstrip().split(" ")
#         for word in s:
#             if not word in stop_words:
#                 sum2.append(word)
# sums.append(sum2)
# sum3 = []
# with open("yelp-3-sum") as fp:
#     for line in fp:
#         s = line.rstrip().split("\n")[0]
#         s = s.rstrip().split(" ")
#         for word in s:
#             if not word in stop_words:
#                 sum3.append(word)
# sums.append(sum3)

def compute_genericity(summaries, summary):
    summaries = [set(sum) for sum in summaries]
    idf = 0
    for word in summary:
        count = 0
        for sum in summaries:
            count += (word in sum)
        idf += len(summaries) / count
    idf /= len(summary)
    print("genericity:", idf)

# compute_faithfulness(doc, sum)

# compute_factuality(doc, sum)

# print(compute_genericity(sums, sums[0]))
# print(compute_genericity(sums, sums[1]))
# print(compute_genericity(sums, sums[2]))
